
input {

  file {
    path => ["/path/to/elasticsearch.log"]
    type => "elasticsearch"
    codec => multiline {
      pattern => "^\["
      negate  => true
      what    => "previous"
    }
  }
  
  file {
    path => ["/path/to/elasticsearch_index_search_slowlog"]
    type => "es_slow_query"
  }
}

filter {

  if [type] == "elasticsearch" {

    grok {
      match => { "message" => "%{DATESTAMP:timestamp}\]\[%{WORD:level}\s*\]\[%{NOTSPACE:module}\s*\]( \[%{NOTSPACE:node}\s*\])? %{GREEDYDATA:es_message}" }
    }

    date {
      match => ["timestamp","YY-MM-dd HH:mm:ss,SSS"]
    }

    if !("_grokparsefailure" in [tags]) {
      mutate {
        remove_field => [ "message" ]
      }
    }

    if [module] == "action.bulk" {
      # Extract index, type and error
      grok {
        match => { "es_message" => "(?m)\[%{HOSTNAME:[elastic][index]}\]\[[0-9]+\] %{GREEDYDATA:[elastic][error]} \{\[[a-zA-Z0-9._-]+\]\[%{USERNAME:[elastic][indexing_type]}\]" }
      }

      # Extract exception
      grok {
        match => { "es_message" => [ "(?m)MapperParsingException\[%{GREEDYDATA:[elastic][parsing_exception]}\];\s+at org.elasticsearch.index.mapper",
                                     "(?m)MapperParsingException\[%{GREEDYDATA:[elastic][parsing_exception]}\]\s+at org.elasticsearch.index.mapper",
                                     "(?m)ProcessClusterEventTimeoutException\[%{GREEDYDATA:[elastic][parsing_exception]}\]\s+at org.elasticsearch.cluster.service" ] }
      }


      # Extract source host that generated log
      grok {
        match => { "es_message" => "(?m)\"host\":\"%{HOSTNAME:[elastic][source_host]}\"" }
      }

    }

  }

  if [type] == "es_slow_query" {

    grok {
      match => { "message" => "%{DATESTAMP:timestamp}\]\[%{WORD:level}\s*\]\[%{NOTSPACE:module}\s*\]( \[%{NOTSPACE:node}\s*\])?( \[%{NOTSPACE:index}\]\[%{NUMBER:index_shard}\])? took\[%{NOTSPACE:took}\], took_millis\[%{NUMBER:took_millis}\], types\[(%{NOTSPACE:types})?\], stats\[(%{NOTSPACE:stats})?\], search_type\[(%{NOTSPACE:search_type})?\], total_shards\[%{NUMBER:total_shards}\], source\[%{GREEDYDATA:source_query}\], extra_source\[(%{GREEDYDATA:extra_source})?\]," }
    }

    date {
      match => ["timestamp","YY-MM-dd HH:mm:ss,SSS"]
    }

    grok {
      match => { "source_query" => "{\"range\":{\"@timestamp\":{\"gte\":%{NUMBER:query_time_gte},\"lte\":%{NUMBER:query_time_lte},\"format\":\"epoch_millis\"}}}" }
      match => { "source_query" => "{\"range\":{\"@timestamp\":{\"to\":\"now-%{DATA:query_time_to}\",\"from\":\"now-%{DATA:query_time_from}\"}}}" }
      match => { "source_query" => "{\"range\":{\"@timestamp\":{\"to\":\"%{DATA:query_time_date_to}\",\"from\":\"%{DATA:query_time_date_from}\"}}}" }
    }

    if [query_time_date_to] {
      ruby {
        code => "event['query_time_range_minutes'] = (( DateTime.parse(event['query_time_date_to']) - DateTime.parse(event['query_time_date_from']) ) * 24 * 60 ).to_i"
      }
    }

    if [query_time_gte] {
      ruby {
        code => "event['query_time_range_minutes'] = (event['query_time_lte'].to_i - event['query_time_gte'].to_i)/1000/60"
      }

      ruby {
        code => "event['query_time_date_to'] = DateTime.strptime(event['query_time_lte'],'%Q').to_s"
      }

      ruby {
        code => "event['query_time_date_from'] = DateTime.strptime(event['query_time_gte'],'%Q').to_s"
      }
    }

  }

}
